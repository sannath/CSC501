{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "#Punctuations\n",
    "import string\n",
    "#reg Expressions\n",
    "import re\n",
    "#emojis with description\n",
    "import demoji\n",
    "#sentences to words\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "#paras to sentences\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#stopwords\n",
    "from nltk.corpus import stopwords\n",
    "#for converting word to vector\n",
    "import gensim.models.word2vec as w2v\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tweet_data = pd.read_csv(\"merged_csv_en_rs_it.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftTroll_data =  tweet_data[(tweet_data['account_category'] == 'LeftTroll')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftTroll_data['date'] = pd.to_datetime(leftTroll_data['publish_date'])\n",
    "leftTroll_data['YEAR']=pd.to_datetime(leftTroll_data.date,format='%Y-%m-%d %H:%M:%S').dt.year\n",
    "leftTroll_data['MONTH']=pd.to_datetime(leftTroll_data.date,format='%Y-%m-%d %H:%M:%S').dt.month\n",
    "leftTroll_data['DAY']=pd.to_datetime(leftTroll_data.date,format='%Y-%m-%d %H:%M:%S').dt.day\n",
    "leftTroll_data2016 = leftTroll_data[(leftTroll_data['YEAR'] == 2016)]\n",
    "leftTroll_data2017 = leftTroll_data[(leftTroll_data['YEAR'] == 2017)]\n",
    "leftTroll_data2018 = leftTroll_data[(leftTroll_data['YEAR'] == 2018)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chron2016=pd.DataFrame(leftTroll_data2016.groupby(['MONTH','DAY']).count()).reset_index().rename(columns={'content':'Total Tweet'})[['MONTH','DAY','Total Tweet']]\n",
    "chron2016=chron2016.pivot('DAY','MONTH','Total Tweet')\n",
    "chron2017=pd.DataFrame(leftTroll_data2017.groupby(['MONTH','DAY']).count()).reset_index().rename(columns={'content':'Total Tweet'})[['MONTH','DAY','Total Tweet']]\n",
    "chron2017=chron2017.pivot('DAY','MONTH','Total Tweet')\n",
    "chron2018=pd.DataFrame(leftTroll_data2018.groupby(['MONTH','DAY']).count()).reset_index().rename(columns={'content':'Total Tweet'})[['MONTH','DAY','Total Tweet']]\n",
    "chron2018=chron2018.pivot('DAY','MONTH','Total Tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Variation in Number of tweets per day for Left Troll in the year 2016', fontsize=14)\n",
    "sns.heatmap(chron2016,annot=True,fmt='g', cmap='viridis',linecolor='grey',linewidths=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Variation in Number of tweets per day for Left Troll in the year 2017', fontsize=14)\n",
    "sns.heatmap(chron2017,annot=True,fmt='g', cmap='seismic',linecolor='grey',linewidths=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(12,10))\n",
    "#plt.title('Variation in Number of tweets per day for Left Troll in the year 2018', fontsize=14)\n",
    "#sns.heatmap(chron2018,annot=True,fmt='g', cmap='viridis',linecolor='grey',linewidths=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leftTroll_dataEnglish = leftTroll_data[(leftTroll_data['language'] == 'English')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hashtags(tweet):\n",
    "    hashtags_list = []\n",
    "    if len(re.findall(\"(#[^#\\s]+)\", tweet)) > 0:\n",
    "        hashtags_list.append(re.findall(\"(#[^#\\s]+)\", tweet))\n",
    "    else:\n",
    "        hashtags_list.append([\"0\"])\n",
    "    return hashtags_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hashtags = leftTroll_data['content'].map(extract_hashtags).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneList_hashtags = []\n",
    "for i in all_hashtags:\n",
    "    for j in i:\n",
    "            oneList_hashtags.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneList_hashtags_series = pd.Series(oneList_hashtags)\n",
    "hashtag_counts = oneList_hashtags_series.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hashtag terms from the series and convert to list\n",
    "hashes = oneList_hashtags_series.values\n",
    "hashes = hashes.tolist()\n",
    "\n",
    "# convert list to one string with all the words\n",
    "hashes_words = \" \".join(hashes)\n",
    "\n",
    "# generate the wordcloud. the max_words argument controls the number of words on the cloud\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(width= 1600, height = 800, \n",
    "                      relative_scaling = 1.0, \n",
    "                      colormap = \"Blues\",\n",
    "                     max_words = 100).generate(hashes_words)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "# use unstack()\n",
    "leftTroll_data.groupby(['author','region']).count()['content'].unstack().plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def getRetweets(text):\n",
    "    for string in text:\n",
    "        if isinstance(string,str):\n",
    "            tokens = string.split(' ')\n",
    "            if tokens[0] == 'RT' and tokens[1].startswith('@'):\n",
    "                yield tokens[1]\n",
    "\n",
    "\n",
    "retweets = getRetweets(leftTroll_dataEnglish['content'])\n",
    "retweet_frequency = Counter(retweets)\n",
    "#retweet_frequency.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "top30 = retweet_frequency.most_common(30)\n",
    "keys = [x[0] for x in top30]\n",
    "vals = [x[1] for x in top30]\n",
    "xpos = range(len(vals),0,-1)\n",
    "plt.barh(xpos, vals)\n",
    "plt.yticks(xpos,keys)\n",
    "plt.title(\"Retweets\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
