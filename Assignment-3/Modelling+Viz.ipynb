{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib_venn import venn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "file = pd.read_csv('soc-redditHyperlinks-title.tsv', delimiter='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_clust(elem):\n",
    "    return(elem[1])\n",
    "\n",
    "def custom_func(elem):\n",
    "    return(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No:of Vertices - 54075\n",
      "Wall time: 152 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "u_source = file['SOURCE_SUBREDDIT'].unique().tolist()\n",
    "u_target = file['TARGET_SUBREDDIT'].unique().tolist()\n",
    "u_source.extend(u_target)\n",
    "Vertices_list = list(dict.fromkeys(u_source))\n",
    "Vertices_list.sort()\n",
    "print(\"No:of Vertices -\",len(Vertices_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No:of Unique Edges - 234792\n",
      "Wall time: 988 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Edges_l = list(zip(file['SOURCE_SUBREDDIT'],file['TARGET_SUBREDDIT']))\n",
    "Edges_l.sort()\n",
    "Edges_list = list(dict.fromkeys(Edges_l))\n",
    "print(\"No:of Unique Edges -\",len(Edges_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of adjacency matrix and adj list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "V = len(Vertices_list)\n",
    "\n",
    "Adj_Mat = np.zeros((V,V),dtype=int)\n",
    "\n",
    "Adj_list = []\n",
    "for s in range(V):\n",
    "    Adj_list.append([])\n",
    "\n",
    "for i in Edges_list:\n",
    "    a = Vertices_list.index(i[0])\n",
    "    b = Vertices_list.index(i[1])\n",
    "    Adj_Mat[a][b]=1\n",
    "    Adj_list[a].append(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of adjacency list \n",
    "#to check wall time for adjacency list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# V = len(Vertices_list)\n",
    "\n",
    "# # Adj_Mat = np.zeros((V,V),dtype=int)\n",
    "\n",
    "# Adj_list = []\n",
    "# for s in range(V):\n",
    "#     Adj_list.append([])\n",
    "\n",
    "# for i in Edges_list:\n",
    "#     a = Vertices_list.index(i[0])\n",
    "#     b = Vertices_list.index(i[1])\n",
    "# #     Adj_Mat[a][b]=1\n",
    "#     Adj_list[a].append(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stroing Adj matrix and Adj list as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt('Adjacency_Matrix.csv',Adj_Mat,delimiter = ',')\n",
    "# np.savetxt('Adjacency_list.csv',Adj_list,delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # Insight 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1-1) Nodes from which many outward nodes are connected\n",
    "# using adjacency matrix/adjacency list\n",
    "# rowcount in adj_mat / length of a sub-list in edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 90.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#wall time using adjacency list\n",
    "\n",
    "count_vertex = 0    \n",
    "count = []\n",
    "outdegree_sub = {}\n",
    "for i in range(len(Adj_list)):\n",
    "    count_vertex = len(Adj_list[i])\n",
    "    a = [Vertices_list[i],count_vertex]\n",
    "    count.append(a)\n",
    "    outdegree_sub[Vertices_list[i]] = Adj_list[i]\n",
    "# outdegree_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# wall time using adjacency matrix\n",
    "\n",
    "count = []\n",
    "for i in range(len(Adj_Mat)):\n",
    "    count_vertex = Adj_Mat[i].sum()\n",
    "#     print(count_vertex)\n",
    "    a = [Vertices_list[i],count_vertex]\n",
    "    count.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count\n",
    "# outdegree_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count.sort(key=custom_func,reverse=True)\n",
    "count\n",
    "count1 = count[:20]\n",
    "popularName = [x[0] for x in count1]\n",
    "popularNo = [x[1] for x in count1]\n",
    "y_pos = np.arange(len(popularName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] =  [14, 8]\n",
    "plt.bar(y_pos, popularNo, align='center', alpha=0.8,color='#F78F1E')\n",
    "plt.xticks(y_pos, popularName,rotation='vertical')\n",
    "plt.ylabel('Connections')\n",
    "plt.title('Popular Subreddits')\n",
    "plt.show()\n",
    "# plt.savefig(\"Popular_subreddits\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insight - 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popular among popular connections\n",
    "popularName1 = []\n",
    "commonCount = []\n",
    "commonName = []\n",
    "for s in popularName:\n",
    "    common_sub = list(set(outdegree_sub[s]) & set(popularName))\n",
    "    popularName1.append(s)\n",
    "    commonCount.append(len(common_sub))\n",
    "    commonName.append((common_sub))\n",
    "    \n",
    "# print(popularName1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = np.arange(len(popularName1))\n",
    "plt.rcParams[\"figure.figsize\"] =  [14, 8]\n",
    "plt.bar(y_pos, commonCount, align='center', alpha=0.8,color='#F78F1E')\n",
    "plt.xticks(y_pos, popularName1,rotation='vertical')\n",
    "plt.ylabel('Connections Among Popular Subrediits')\n",
    "plt.title('Popular Subreddits')\n",
    "plt.show()\n",
    "# plt.savefig(\"Popular_subreddits\",dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d3 chord diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3matrix = []\n",
    "d3matrix = np.zeros((len(popularName1),len(popularName1)),dtype=int)\n",
    "matrix_index = 0\n",
    "for name in commonName:\n",
    "    for name1 in name:\n",
    "        a = popularName1.index(name1)\n",
    "        d3matrix[matrix_index][a] = 1\n",
    "#         print(a)\n",
    "    matrix_index = matrix_index+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# popularName1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# wall time using adjacency matrix\n",
    "\n",
    "count = []\n",
    "for i in range(len(Adj_Mat)):\n",
    "    count_vertex = Adj_Mat[i].sum()\n",
    "#     print(count_vertex)\n",
    "    a = [Vertices_list[i],count_vertex]\n",
    "    count.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x = []\n",
    "# y = []\n",
    "# for i in range(20):\n",
    "#     x.append(count[i][0])\n",
    "#     y.append(count[i][1])    \n",
    "\n",
    "# plt.figure(figsize=(12,8))\n",
    "# plt.barh(x,y)\n",
    "# plt.title(\"top 20 popuplar sub-reddits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_ADJ_MAT_ind = []\n",
    "# for i in range(len(x)):\n",
    "#     sub_ADJ_MAT_ind.append(Vertices_list.index(x[i]))\n",
    "\n",
    "# sub_ADJ_MAT_ind.sort()\n",
    "# Adj_Mat[sub_ADJ_MAT_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1-2) Nodes to which many nodes are connected (inward connecteions)\n",
    "#  using adjacency matrix\n",
    "# Col_count in adj_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# x1   = []\n",
    "# y1   = []\n",
    "# count_col = Adj_Mat.sum(axis=0)\n",
    "# Col_list = count_col.tolist()\n",
    "# Col_list_dup = count_col.tolist()\n",
    "\n",
    "# for i in range(20):\n",
    "#     mx = max(Col_list)   \n",
    "    \n",
    "#     indd = Col_list_dup.index(mx)\n",
    "    \n",
    "#     y1.append(mx)\n",
    "#     x1.append(Vertices_list[indd])\n",
    "#     Col_list.remove(mx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,8))\n",
    "# plt.barh(x1,y1)\n",
    "# plt.title(\"top 20 popuplar sub-reddits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# sub_ADJ_MAT_ind_1 = []\n",
    "# for i in range(len(x1)):\n",
    "#     sub_ADJ_MAT_ind_1.append(Vertices_list.index(x1[i]))\n",
    "\n",
    "# sub_ADJ_MAT_ind_1.sort()\n",
    "# Adj_Mat[:,sub_ADJ_MAT_ind_1]outdegree_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # insight 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2-1) how long a path takes to encounter its first cycle\n",
    "# avg path length for all the paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Vertices(node):\n",
    "    for i in range(len(Vertices_list)):\n",
    "        if node == Vertices_list[i]:\n",
    "#             print(i)\n",
    "            return i\n",
    "\n",
    "def Matrix(index):\n",
    "    for i in range(len(Adj_Mat[index])):\n",
    "        if Adj_Mat[index][i]==1:\n",
    "#             print(Vertices_list[i])\n",
    "            return Vertices_list[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    # insight 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3-1)Categorizing link sentiments of popular subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_sent_popular_nodes = []\n",
    "for i in range(len(x)):\n",
    "    df = file[file['SOURCE_SUBREDDIT']==x[i]]\n",
    "    link_sent_popular_nodes.append(df.LINK_SENTIMENT.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_link_sent = []\n",
    "pos = []\n",
    "neg = []\n",
    "for i in range(len(link_sent_popular_nodes)):\n",
    "    link_sent_popular_nodes[i].sort()\n",
    "    c = Counter(link_sent_popular_nodes[i])\n",
    "    count_link_sent.append(list(c.values()))\n",
    "    pos.append(list(c.values())[1])\n",
    "    neg.append(list(c.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "width = 0.75\n",
    "s1 = np.arange(20)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "p1 = plt.barh(s1,pos, width)\n",
    "p2 = plt.barh(s1,neg, width)\n",
    "\n",
    "plt.ylabel('top 20 popular sub-reddits')\n",
    "plt.xlabel('total #edges from the node')\n",
    "plt.title('Number of Positive and Negative link Sentiments on the outward edges of top 20 popular subreddits')\n",
    "\n",
    "plt.yticks(s1, x)\n",
    "plt.xticks(np.arange(0, 18001, 1000))\n",
    "plt.legend((p1[0], p2[0]), ('positive', 'negative'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(3-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_sent_popular_nodes_1 = []\n",
    "for i in range(len(x1)):\n",
    "    df1 = file[file['TARGET_SUBREDDIT']==x1[i]]\n",
    "    link_sent_popular_nodes_1.append(df1.LINK_SENTIMENT.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_link_sent_1 = []\n",
    "pos_1 = []\n",
    "neg_1 = []\n",
    "for i in range(len(link_sent_popular_nodes_1)):\n",
    "    link_sent_popular_nodes_1[i].sort()\n",
    "    c = Counter(link_sent_popular_nodes_1[i])\n",
    "    count_link_sent_1.append(list(c.values()))\n",
    "    pos_1.append(list(c.values())[1])\n",
    "    neg_1.append(list(c.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s1_1 = np.arange(20)\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "p1_1 = plt.barh(s1_1,pos_1, width)\n",
    "p2_1 = plt.barh(s1_1,neg_1, width)\n",
    "\n",
    "plt.ylabel('top 20 popular sub-reddits')\n",
    "plt.xlabel('total #edges from the node')\n",
    "plt.title('Number of Positive and Negative link Sentiments on the outward edges of top 20 popular subreddits')\n",
    "\n",
    "plt.yticks(s1_1, x1)\n",
    "plt.xticks(np.arange(0, 17001, 1000))\n",
    "plt.legend((p1_1[0], p2_1[0]), ('positive', 'negative'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #insight 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "body  = pd.read_csv('soc-redditHyperlinks-body.tsv', delimiter='\\t')\n",
    "title = pd.read_csv('soc-redditHyperlinks-title.tsv', delimiter='\\t')\n",
    "\n",
    "body_src_list  = body['SOURCE_SUBREDDIT'].unique().tolist()\n",
    "body_trg_list  = body['TARGET_SUBREDDIT'].unique().tolist()\n",
    "\n",
    "body_src_list.extend(body_trg_list)\n",
    "body_list = list(dict.fromkeys(body_src_list))\n",
    "\n",
    "title_src_list = title['SOURCE_SUBREDDIT'].unique().tolist()\n",
    "title_trg_list = title['TARGET_SUBREDDIT'].unique().tolist()\n",
    "\n",
    "title_src_list.extend(title_trg_list)\n",
    "title_list = list(dict.fromkeys(title_src_list))\n",
    "\n",
    "only_body  = list(set(body_list).difference(title_list))\n",
    "only_title = list(set(title_list).difference(body_list))\n",
    "\n",
    "all_V= 55,863\n",
    "\n",
    "print(\"#Nodes which can be visited only through body of the subreddit  :\", len(only_body))\n",
    "print(\"#Nodes which can be visited only through title of the subreddit :\", len(only_title))\n",
    "cnt =  (all_v) - (len(only_body)+len(only_title))\n",
    "print(\"#Nodes which can be visited by body and title :\", cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First way to call the 2 group Venn diagram:\n",
    "venn2(subsets = (len(only_body), len(only_title), cnt), set_labels = ('Body', 'Title'))\n",
    "ax = plt.gca()\n",
    "ax.legend(labels=['ONLY_BODY','ONLY_TITLE','BOTH'], title=\"\")\n",
    "plt.title(\"#nodes that can be visited by only body/only title\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                    #insight 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (4-1) #nodes in path before forming a cycle in the path\n",
    "# also calculating the avg path length until cycle \n",
    "# a subreddit needs  #avg new nodes to be visited to...... (form a cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "path_length = []\n",
    "for node in origin_nodes:\n",
    "    src = node\n",
    "    path = []\n",
    "    trg = ''\n",
    "    path.append(src)\n",
    "    exists=True\n",
    "\n",
    "    while exists:\n",
    "        index = Vertices_list.index(src)\n",
    "        if len(Adj_list[index])>0:\n",
    "            trg   = Adj_list[index][0]  \n",
    "            for element in path:\n",
    "                if element == trg:                    \n",
    "#                     check for next adjacent node\n",
    "                    trg = Adj_list[index][0]  \n",
    "                    exists = False\n",
    "                \n",
    "            if exists:\n",
    "                path.append(trg)\n",
    "                src = trg\n",
    "        else:\n",
    "            exists=False\n",
    "    path_length.append(len(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = 0\n",
    "sum = 0\n",
    "for i in range(len(path_length)):\n",
    "    sum += path_length[i]\n",
    "avg = int(sum/(i+1))\n",
    "print(\"average path length of a path until a cycle is encountered :\", avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
